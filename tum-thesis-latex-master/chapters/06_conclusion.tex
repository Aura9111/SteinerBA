% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Conclusion}\label{chapter:conclusion}

To sum up we started by defining our problem setting, which was a procurement auction with single minded sellers and ourself in the position of an auctioneer trying to procure the minimum cost network that spans a set of required nodes. We then implemented two loss contraction algorithms for this problem setting, which are based on Steiner tree approximation algorithms. Since they both relied on a different algorithm for an initial Steiner tree we provided that as well. We used the Steiner tree problems at SteinLib \cite{Dui93} as testcases for our algorithms. The simplest one was the MST-approximation algorithm, which was used as the initial working tree for the other two algorithms. While its solution trees for our testcases all had decent average total tree costs it was bested by both other algorithms when we compare the average total tree cost and the performance ratio. We then looked at the approximation algorithm presented by Berman and Ramaiyer \cite{BeRa94}, which provided slightly better average tree costs and a significantly better performance ration, by including Steiner nodes, that appeared in subsets of terminals, into the final solution tree. The last algorithm we looked at was the $IRGH$-algorithm by Hougardy and Proemel \cite{HoPr99}, which improved the performance ratio once again. Its average tree cost was also better compared to the other two algoriths, but not consistently. In most cases it managed to out perform the other algorithms with its heuristic, that helped include more Steiner nodes into the tree, allowing it to find more complex solutions, but in some cases this aggressive inclusion of Steiner nodes lead to it increasing upon the cost of the initial MST-approximation. We then proceded to discern whether the algorithms in question would implement strategy proofness or incentive compatibility. This incentive compatibility is required to guarantee, that the dominant strategy for our single-minded sellers is to report their true valuations for the edges, they're selling to us. In order for the algorithms be strategy proof they had to implement monotonicity and had to pay out critical payments to the winning seller. This is due to a Lemma proposed by Blumrosen and Nisan \cite{BlNi07}. We were able to prove monotonicity for MST and Berman, Ramaiyer, while we disproved it for Hougardy, Proemel. Since the average tree cost and performance ratio of Berman, Ramaiyer are strictly better than for the MST-approximation we proceded to only look at Berman, Ramaiyer for the critical payments. We computed these using exponential search and binary search successively. We can now safely conclude, that within the algorithms we looked at in this paper the best algorithm for our proposed setting is the approximation algorithm by Berman and Ramaiyer, since it is strategy proof and has the superior performance ratio, compared to the MST-approximation. The full adaptation of this algorithm to our initially proposed setting would include us as the auctioneer comparing the offered edges using the regular Berman, Ramaiyer algorithm, but changing the payments, that the sellers of the respective edges receive, to the critical payments, that we computed.  